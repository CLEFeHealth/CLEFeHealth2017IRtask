# Assessments for CLEFeHealth2017IRtask

Every document was judged with respect to its topical relevance, understandability and trustworthiness.

In the __2016__ folder you can find the assessments conducted in 2016 task for both tasks 1 (300 queries) and task 2 (50 queries).
Note that the correspondent of 2016's task2 is the 2017's IRtask3.

__*task1.qrels*__ - Topical relevance judgements. Options are 0 (not relevant), 1 (somewhat relevant), 2 (highly relevant)

__*task1.qunder*__ - Understandability judgements.
Represents the subject judgement made by physicians with respect to the understandability of a document. 
Assessors were instructed to perform the assignments as if they were their patients, i.e. if their patients would be able to fully understand the document content.
Options vary from 0 (meaning that a document was deemed as very hard to understand) to 100 (very  easy to understand)

__*task1.qtrust*__ - Trustworthiness judgements. 
Represents the subject judgement made by physicians with respect to the trustworthiness of a document. 
Assessors were instructed to take into consideration as many factors as they wish, including document content (veracity of the content) and presentation (how the html is displayed or the amount of advertisements shown).
Options vary from 0 (meaning that a document was deemed as not trustable) to 100 (very high quality document)
